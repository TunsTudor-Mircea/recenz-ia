{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LaRoSeDa Dataset Exploration\n",
    "\n",
    "This notebook explores the LaRoSeDa Romanian e-commerce review dataset.\n",
    "\n",
    "**Contents:**\n",
    "1. Load and inspect dataset\n",
    "2. Basic statistics\n",
    "3. Class distribution\n",
    "4. Text length analysis\n",
    "5. Word frequency analysis\n",
    "6. Sample reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Download dataset from HuggingFace\n",
    "train_file = hf_hub_download(\n",
    "    repo_id=\"universityofbucharest/laroseda\",\n",
    "    filename=\"laroseda/train/0000.parquet\",\n",
    "    repo_type=\"dataset\",\n",
    "    revision=\"refs/convert/parquet\"\n",
    ")\n",
    "\n",
    "test_file = hf_hub_download(\n",
    "    repo_id=\"universityofbucharest/laroseda\",\n",
    "    filename=\"laroseda/test/0000.parquet\",\n",
    "    repo_type=\"dataset\",\n",
    "    revision=\"refs/convert/parquet\"\n",
    ")\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_parquet(train_file)\n",
    "test_df = pd.read_parquet(test_file)\n",
    "\n",
    "print(f\"Train set: {len(train_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n",
    "print(f\"Total: {len(train_df) + len(test_df)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Show first few rows\n",
    "print(\"First 5 training samples:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Column info\n",
    "print(\"\\nColumn information:\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Star rating distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Train set\n",
    "train_df['starRating'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('Train Set - Star Rating Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Star Rating', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Test set\n",
    "test_df['starRating'].value_counts().sort_index().plot(kind='bar', ax=axes[1], color='lightcoral')\n",
    "axes[1].set_title('Test Set - Star Rating Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Star Rating', fontsize=12)\n",
    "axes[1].set_ylabel('Count', fontsize=12)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTrain set star rating distribution:\")\n",
    "print(train_df['starRating'].value_counts().sort_index())\n",
    "print(\"\\nTest set star rating distribution:\")\n",
    "print(test_df['starRating'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Binary classification distribution (Negative: 1-2 stars, Positive: 3-5 stars)\n",
    "train_df['binary_label'] = train_df['starRating'].apply(lambda x: 'Negative' if x in [1, 2] else 'Positive')\n",
    "test_df['binary_label'] = test_df['starRating'].apply(lambda x: 'Negative' if x in [1, 2] else 'Positive')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Train set\n",
    "train_counts = train_df['binary_label'].value_counts()\n",
    "axes[0].pie(train_counts, labels=train_counts.index, autopct='%1.1f%%', startangle=90, colors=['#ff9999', '#66b3ff'])\n",
    "axes[0].set_title('Train Set - Binary Labels', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Test set\n",
    "test_counts = test_df['binary_label'].value_counts()\n",
    "axes[1].pie(test_counts, labels=test_counts.index, autopct='%1.1f%%', startangle=90, colors=['#ff9999', '#66b3ff'])\n",
    "axes[1].set_title('Test Set - Binary Labels', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nBinary label distribution:\")\n",
    "print(\"Train:\", dict(train_counts))\n",
    "print(\"Test:\", dict(test_counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create combined text column\n",
    "train_df['full_text'] = train_df['title'] + ' ' + train_df['content']\n",
    "test_df['full_text'] = test_df['title'] + ' ' + test_df['content']\n",
    "\n",
    "# Calculate text lengths\n",
    "train_df['text_length'] = train_df['full_text'].str.len()\n",
    "test_df['text_length'] = test_df['full_text'].str.len()\n",
    "\n",
    "train_df['word_count'] = train_df['full_text'].str.split().str.len()\n",
    "test_df['word_count'] = test_df['full_text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Text length statistics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Character length distribution\n",
    "axes[0, 0].hist(train_df['text_length'], bins=50, alpha=0.7, label='Train', color='skyblue', edgecolor='black')\n",
    "axes[0, 0].hist(test_df['text_length'], bins=50, alpha=0.7, label='Test', color='lightcoral', edgecolor='black')\n",
    "axes[0, 0].set_title('Text Length Distribution (Characters)', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Character Count', fontsize=10)\n",
    "axes[0, 0].set_ylabel('Frequency', fontsize=10)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Word count distribution\n",
    "axes[0, 1].hist(train_df['word_count'], bins=50, alpha=0.7, label='Train', color='skyblue', edgecolor='black')\n",
    "axes[0, 1].hist(test_df['word_count'], bins=50, alpha=0.7, label='Test', color='lightcoral', edgecolor='black')\n",
    "axes[0, 1].set_title('Word Count Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Word Count', fontsize=10)\n",
    "axes[0, 1].set_ylabel('Frequency', fontsize=10)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Box plot by sentiment\n",
    "train_df.boxplot(column='word_count', by='binary_label', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Word Count by Sentiment (Train)', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Sentiment', fontsize=10)\n",
    "axes[1, 0].set_ylabel('Word Count', fontsize=10)\n",
    "plt.sca(axes[1, 0])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Average word count by star rating\n",
    "avg_words = train_df.groupby('starRating')['word_count'].mean()\n",
    "avg_words.plot(kind='bar', ax=axes[1, 1], color='lightgreen', edgecolor='black')\n",
    "axes[1, 1].set_title('Average Word Count by Star Rating', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Star Rating', fontsize=10)\n",
    "axes[1, 1].set_ylabel('Average Word Count', fontsize=10)\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "plt.sca(axes[1, 1])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Summary statistics\n",
    "print(\"\\nText Length Statistics (Train Set):\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Character count - Mean: {train_df['text_length'].mean():.1f}, Median: {train_df['text_length'].median():.1f}\")\n",
    "print(f\"Character count - Min: {train_df['text_length'].min()}, Max: {train_df['text_length'].max()}\")\n",
    "print(f\"Word count - Mean: {train_df['word_count'].mean():.1f}, Median: {train_df['word_count'].median():.1f}\")\n",
    "print(f\"Word count - Min: {train_df['word_count'].min()}, Max: {train_df['word_count'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Word Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get all words\n",
    "all_words = ' '.join(train_df['full_text'].str.lower()).split()\n",
    "word_freq = Counter(all_words)\n",
    "\n",
    "# Top 30 most common words\n",
    "top_words = word_freq.most_common(30)\n",
    "words, counts = zip(*top_words)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.barh(range(len(words)), counts, color='steelblue')\n",
    "plt.yticks(range(len(words)), words)\n",
    "plt.xlabel('Frequency', fontsize=12, fontweight='bold')\n",
    "plt.title('Top 30 Most Common Words', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 10 most common words:\")\n",
    "for word, count in top_words[:10]:\n",
    "    print(f\"{word:20s}: {count:6d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Word frequency by sentiment\n",
    "negative_words = ' '.join(train_df[train_df['binary_label'] == 'Negative']['full_text'].str.lower()).split()\n",
    "positive_words = ' '.join(train_df[train_df['binary_label'] == 'Positive']['full_text'].str.lower()).split()\n",
    "\n",
    "negative_freq = Counter(negative_words)\n",
    "positive_freq = Counter(positive_words)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Negative reviews\n",
    "neg_top = negative_freq.most_common(20)\n",
    "words, counts = zip(*neg_top)\n",
    "axes[0].barh(range(len(words)), counts, color='#ff9999')\n",
    "axes[0].set_yticks(range(len(words)))\n",
    "axes[0].set_yticklabels(words)\n",
    "axes[0].set_xlabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Top 20 Words in Negative Reviews', fontsize=14, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Positive reviews\n",
    "pos_top = positive_freq.most_common(20)\n",
    "words, counts = zip(*pos_top)\n",
    "axes[1].barh(range(len(words)), counts, color='#66b3ff')\n",
    "axes[1].set_yticks(range(len(words)))\n",
    "axes[1].set_yticklabels(words)\n",
    "axes[1].set_xlabel('Frequency', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title('Top 20 Words in Positive Reviews', fontsize=14, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sample Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Show sample reviews for each star rating\n",
    "print(\"\\nSample Reviews by Star Rating:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for rating in sorted(train_df['starRating'].unique()):\n",
    "    print(f\"\\n{rating}-Star Reviews:\")\n",
    "    print(\"-\"*80)\n",
    "    samples = train_df[train_df['starRating'] == rating].sample(min(2, len(train_df[train_df['starRating'] == rating])))\n",
    "    for idx, row in samples.iterrows():\n",
    "        print(f\"\\nTitle: {row['title']}\")\n",
    "        print(f\"Content: {row['content'][:200]}...\" if len(row['content']) > 200 else f\"Content: {row['content']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook explored the LaRoSeDa dataset:\n",
    "\n",
    "1. **Dataset Size**: 12,000 train / 3,000 test samples\n",
    "2. **Class Distribution**: Binary classification (Negative: 1-2 stars, Positive: 3-5 stars)\n",
    "3. **Text Length**: Varies widely, with average around 50-100 words per review\n",
    "4. **Language**: Romanian e-commerce product reviews\n",
    "5. **Word Patterns**: Different frequent words appear in positive vs negative reviews\n",
    "\n",
    "The dataset is suitable for binary sentiment classification with clear positive/negative signals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
